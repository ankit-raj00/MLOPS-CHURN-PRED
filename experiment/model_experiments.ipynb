{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Experimentation with MLflow\n",
                "\n",
                "In this notebook, we will:\n",
                "1.  **Preprocessing**: Implement the full pipeline (KNN Imputation -> One-Hot Encoding -> Scaling).\n",
                "2.  **Experiment**: Train Logistic Regression, Random Forest, and XGBoost.\n",
                "3.  **Track**: Use MLflow to log parameters, metrics, and models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "eeab8712",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<Experiment: artifact_location='file:d:/MLOPS PROJECT CHURN PRED/experiment/../mlruns/124876933937949882', creation_time=1767696233341, experiment_id='124876933937949882', last_update_time=1767696233341, lifecycle_stage='active', name='Churn_Prediction_Experiments', tags={'mlflow.experimentKind': 'custom_model_development'}>"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import mlflow\n",
                "import mlflow.sklearn\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
                "\n",
                "%matplotlib inline\n",
                "\n",
                "# Set MLflow Tracking URI (Local)\n",
                "# Using ../mlruns to save it in the PROJECT ROOT, so mlflow ui can find it easily from terminal\n",
                "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
                "mlflow.set_experiment(\"Churn_Prediction_Experiments\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ad3260f0",
            "metadata": {},
            "source": [
                "## 1. Load and Split Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "bc356ac5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape: (12800, 10)\n",
                        "Test Shape: (3200, 10)\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv('../customer_churn_dataset/train.csv')\n",
                "\n",
                "# Separate Features and Target\n",
                "X = df.drop('churn', axis=1)\n",
                "y = df['churn'].apply(lambda x: 1 if x == 'Yes' else 0)  # Binary Target\n",
                "\n",
                "# Train/Test Split (Before any processing to avoid leakage)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "print(\"Train Shape:\", X_train.shape)\n",
                "print(\"Test Shape:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f095c5c2",
            "metadata": {},
            "source": [
                "## 2. Preprocessing Pipeline Implementation\n",
                "We need to apply the KNN Imputation logic here on the Split data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "c66588af",
            "metadata": {},
            "outputs": [],
            "source": [
                "def impute_internet_service(X_data, knn_model=None, scaler=None, is_train=True):\n",
                "    \"\"\"\n",
                "    Applies KNN imputation to 'internet_service' column.\n",
                "    If is_train=True, it fits the KNN model.\n",
                "    If is_train=False, it uses the passed model.\n",
                "    \"\"\"\n",
                "    X = X_data.copy()\n",
                "    impute_features = ['monthly_charges', 'total_charges', 'tenure']\n",
                "    \n",
                "    # Standard Scale the features used for KNN\n",
                "    if is_train:\n",
                "        scaler = StandardScaler()\n",
                "        scaler.fit(X[impute_features])\n",
                "    \n",
                "    X_scaled = scaler.transform(X[impute_features])\n",
                "    \n",
                "    # Separate missing\n",
                "    mask_missing = X['internet_service'].isnull()\n",
                "    \n",
                "    if is_train:\n",
                "        # Train KNN\n",
                "        X_train_knn = X_scaled[~mask_missing]\n",
                "        y_train_knn = X.loc[~mask_missing, 'internet_service']\n",
                "        \n",
                "        knn_model = KNeighborsClassifier(n_neighbors=5)\n",
                "        knn_model.fit(X_train_knn, y_train_knn)\n",
                "    \n",
                "    # Predict if there are missing values\n",
                "    if mask_missing.sum() > 0:\n",
                "        X_missing_knn = X_scaled[mask_missing]\n",
                "        imputed_values = knn_model.predict(X_missing_knn)\n",
                "        X.loc[mask_missing, 'internet_service'] = imputed_values\n",
                "        \n",
                "    return X, knn_model, scaler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "2b37e2bf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Imputing Training Data...\n",
                        "Imputing Test Data...\n",
                        "Missing in Train: 0\n",
                        "Missing in Test: 0\n"
                    ]
                }
            ],
            "source": [
                "# Apply Imputation\n",
                "print(\"Imputing Training Data...\")\n",
                "X_train_imp, knn_imputer, knn_scaler = impute_internet_service(X_train, is_train=True)\n",
                "\n",
                "print(\"Imputing Test Data...\")\n",
                "X_test_imp, _, _ = impute_internet_service(X_test, knn_model=knn_imputer, scaler=knn_scaler, is_train=False)\n",
                "\n",
                "# Check missing\n",
                "print(\"Missing in Train:\", X_train_imp.isnull().sum().sum())\n",
                "print(\"Missing in Test:\", X_test_imp.isnull().sum().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "b084d3c9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Final Train Shape: (12800, 16)\n"
                    ]
                }
            ],
            "source": [
                "# Encoding and Final Scaling\n",
                "numerical_cols = ['tenure', 'monthly_charges', 'total_charges']\n",
                "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
                "\n",
                "# Remove target or ID if present (customer_id is usually not useful for prediction)\n",
                "if 'customer_id' in categorical_cols: categorical_cols.remove('customer_id')\n",
                "\n",
                "# One-Hot Encoding\n",
                "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
                "X_train_encoded = ohe.fit_transform(X_train_imp[categorical_cols])\n",
                "X_test_encoded = ohe.transform(X_test_imp[categorical_cols])\n",
                "\n",
                "# Get feature names\n",
                "encoded_features = ohe.get_feature_names_out(categorical_cols)\n",
                "\n",
                "# Scaling Numerical\n",
                "scaler_final = StandardScaler()\n",
                "X_train_scaled = scaler_final.fit_transform(X_train_imp[numerical_cols])\n",
                "X_test_scaled = scaler_final.transform(X_test_imp[numerical_cols])\n",
                "\n",
                "# Combine\n",
                "X_train_final = np.hstack([X_train_scaled, X_train_encoded])\n",
                "X_test_final = np.hstack([X_test_scaled, X_test_encoded])\n",
                "\n",
                "print(\"Final Train Shape:\", X_train_final.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "468be2db",
            "metadata": {},
            "source": [
                "## 3. Run Experiments with MLflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "3ca1bcc0",
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_experiment(model, name, params):\n",
                "    with mlflow.start_run(run_name=name):\n",
                "        # Log Params\n",
                "        mlflow.log_params(params)\n",
                "        \n",
                "        # Train\n",
                "        model.fit(X_train_final, y_train)\n",
                "        \n",
                "        # Predict\n",
                "        y_pred = model.predict(X_test_final)\n",
                "        y_prob = model.predict_proba(X_test_final)[:, 1] if hasattr(model, 'predict_proba') else None\n",
                "        \n",
                "        # Metrics\n",
                "        acc = accuracy_score(y_test, y_pred)\n",
                "        prec = precision_score(y_test, y_pred)\n",
                "        rec = recall_score(y_test, y_pred)\n",
                "        f1 = f1_score(y_test, y_pred)\n",
                "        roc = roc_auc_score(y_test, y_prob) if y_prob is not None else 0\n",
                "        \n",
                "        # Log Metrics\n",
                "        mlflow.log_metric(\"accuracy\", acc)\n",
                "        mlflow.log_metric(\"precision\", prec)\n",
                "        mlflow.log_metric(\"recall\", rec)\n",
                "        mlflow.log_metric(\"f1_score\", f1)\n",
                "        mlflow.log_metric(\"auc_roc\", roc)\n",
                "        \n",
                "        # Log Model \n",
                "        # FIX: explicitly using 'name' argument instead of 'artifact_path' for MLflow 3.x+\n",
                "        mlflow.sklearn.log_model(model, name=name)\n",
                "        \n",
                "        print(f\"Finished {name}: Acc={acc:.4f}, F1={f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "1c0ee6c6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Finished Logistic_Regression: Acc=0.7341, F1=0.5347\n",
                        "Finished Random_Forest: Acc=0.7784, F1=0.5876\n",
                        "Finished XGBoost: Acc=0.7788, F1=0.5889\n"
                    ]
                }
            ],
            "source": [
                "# 1. Logistic Regression\n",
                "lr_params = {'max_iter': 1000, 'solver': 'lbfgs'}\n",
                "run_experiment(LogisticRegression(**lr_params), \"Logistic_Regression\", lr_params)\n",
                "\n",
                "# 2. Random Forest\n",
                "rf_params = {'n_estimators': 100, 'max_depth': 10, 'random_state': 42}\n",
                "run_experiment(RandomForestClassifier(**rf_params), \"Random_Forest\", rf_params)\n",
                "\n",
                "# 3. XGBoost\n",
                "xgb_params = {'n_estimators': 100, 'learning_rate': 0.1, 'eval_metric': 'logloss'}\n",
                "run_experiment(XGBClassifier(**xgb_params), \"XGBoost\", xgb_params)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

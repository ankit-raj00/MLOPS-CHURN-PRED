{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Gap Analysis & Replication\n",
                "\n",
                "**Goal**: Replicate the high performance (F1 ~0.76+, Recall ~0.86) observed in the reference code.\n",
                "**Hypothesis**: The difference is in Preprocessing.\n",
                "1.  **Imputation**: We will **NOT** use KNN. We will let models handle missing values (or fill with a placeholder).\n",
                "2.  **Encoding**: We will use **Label Encoding** instead of One-Hot Encoding.\n",
                "3.  **Data**: We will use the full `customer_churn_dataset.csv` directly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\MLOPS PROJECT CHURN PRED\\customer_venc\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
                        "  return FileStore(store_uri, store_uri)\n",
                        "2026/01/06 16:54:40 INFO mlflow.tracking.fluent: Experiment with name 'Churn_Prediction_Gap_Analysis' does not exist. Creating a new experiment.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Experiment: artifact_location='file:d:/MLOPS PROJECT CHURN PRED/experiment/../mlruns/873684746974737577', creation_time=1767698680713, experiment_id='873684746974737577', last_update_time=1767698680713, lifecycle_stage='active', name='Churn_Prediction_Gap_Analysis', tags={}>"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import mlflow\n",
                "import mlflow.sklearn\n",
                "import mlflow.lightgbm\n",
                "import mlflow.catboost\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "from catboost import CatBoostClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score\n",
                "\n",
                "%matplotlib inline\n",
                "\n",
                "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
                "mlflow.set_experiment(\"Churn_Prediction_Gap_Analysis\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data (Mimic Reference)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Missing after basic fill:\n",
                        "tenure              0\n",
                        "monthly_charges     0\n",
                        "total_charges       0\n",
                        "contract            0\n",
                        "payment_method      0\n",
                        "internet_service    0\n",
                        "tech_support        0\n",
                        "online_security     0\n",
                        "support_calls       0\n",
                        "churn               0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Load the FULL dataset (as referenced in user's snippet)\n",
                "df = pd.read_csv('../customer_churn_dataset/customer_churn_dataset.csv')\n",
                "\n",
                "# Drop ID\n",
                "if 'customer_id' in df.columns:\n",
                "    df.drop(\"customer_id\", axis=1, inplace=True)\n",
                "\n",
                "# Missing Values Strategy: \n",
                "# Reference code doesn't explicitly impute, so we suspect they allow LightGBM/CatBoost to handle it \n",
                "# OR they fill with a specific value implicitly.\n",
                "# Let's fill NA with \"Unknown\" for Categorical to be safe and clear.\n",
                "for col in df.columns:\n",
                "    if df[col].dtype == 'object':\n",
                "        df[col] = df[col].fillna(\"Unknown\")\n",
                "    else:\n",
                "        # For numeric, if any missing, fill with median (or keep as NaN for Boosters)\n",
                "        # The 'internet_service' missing values were the main issue. They are categorical.\n",
                "        pass\n",
                "\n",
                "print(\"Missing after basic fill:\")\n",
                "print(df.isnull().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Label Encoding (Mimic Reference)\n",
                "Instead of OHE, we convert strings to integers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Encoded contract\n",
                        "Encoded payment_method\n",
                        "Encoded internet_service\n",
                        "Encoded tech_support\n",
                        "Encoded online_security\n",
                        "Encoded churn\n",
                        "Target distribution:\n",
                        "churn\n",
                        "0    13157\n",
                        "1     6843\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "le = LabelEncoder()\n",
                "for col in df.columns:\n",
                "    if df[col].dtype == 'object':\n",
                "        df[col] = le.fit_transform(df[col])\n",
                "        print(f\"Encoded {col}\")\n",
                "\n",
                "# Convert target to int if not already (LabelEncoder handles it usually, but let's be sure)\n",
                "# Check target column name (usually 'churn' or similar)\n",
                "target_col = 'churn' # Verify this name\n",
                "print(f\"Target distribution:\\n{df[target_col].value_counts()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Split & Train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape: (16000, 9)\n",
                        "Test Shape: (4000, 9)\n"
                    ]
                }
            ],
            "source": [
                "X = df.drop(target_col, axis=1)\n",
                "y = df[target_col]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "print(\"Train Shape:\", X_train.shape)\n",
                "print(\"Test Shape:\", X_test.shape)\n",
                "\n",
                "def train_simple(model, name):\n",
                "    with mlflow.start_run(run_name=name):\n",
                "        print(f\"Training {name}...\")\n",
                "        model.fit(X_train, y_train)\n",
                "        \n",
                "        y_pred = model.predict(X_test)\n",
                "        \n",
                "        acc = accuracy_score(y_test, y_pred)\n",
                "        f1 = f1_score(y_test, y_pred)\n",
                "        \n",
                "        mlflow.log_metric(\"accuracy\", acc)\n",
                "        mlflow.log_metric(\"f1_score\", f1)\n",
                "        \n",
                "        print(f\"Finished {name}: Acc={acc:.4f}, F1={f1:.4f}\")\n",
                "        print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training RF_LabelEncoded_Balanced...\n",
                        "Finished RF_LabelEncoded_Balanced: Acc=0.8393, F1=0.7348\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.94      0.88      2631\n",
                        "           1       0.84      0.65      0.73      1369\n",
                        "\n",
                        "    accuracy                           0.84      4000\n",
                        "   macro avg       0.84      0.79      0.81      4000\n",
                        "weighted avg       0.84      0.84      0.83      4000\n",
                        "\n",
                        "Training LGBM_LabelEncoded_Balanced...\n",
                        "Finished LGBM_LabelEncoded_Balanced: Acc=0.8383, F1=0.7358\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.93      0.88      2631\n",
                        "           1       0.83      0.66      0.74      1369\n",
                        "\n",
                        "    accuracy                           0.84      4000\n",
                        "   macro avg       0.84      0.80      0.81      4000\n",
                        "weighted avg       0.84      0.84      0.83      4000\n",
                        "\n",
                        "Training Cat_LabelEncoded_Balanced...\n",
                        "Finished Cat_LabelEncoded_Balanced: Acc=0.8420, F1=0.7399\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.94      0.89      2631\n",
                        "           1       0.85      0.66      0.74      1369\n",
                        "\n",
                        "    accuracy                           0.84      4000\n",
                        "   macro avg       0.84      0.80      0.81      4000\n",
                        "weighted avg       0.84      0.84      0.84      4000\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# 1. Random Forest (Balanced)\n",
                "rf = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
                "train_simple(rf, \"RF_LabelEncoded_Balanced\")\n",
                "\n",
                "# 2. LightGBM (Balanced)\n",
                "lgbm = LGBMClassifier(n_estimators=200, class_weight='balanced', random_state=42, verbosity=-1)\n",
                "train_simple(lgbm, \"LGBM_LabelEncoded_Balanced\")\n",
                "\n",
                "# 3. CatBoost (Balanced)\n",
                "cat = CatBoostClassifier(iterations=200, auto_class_weights='Balanced', random_seed=42, verbose=0)\n",
                "train_simple(cat, \"Cat_LabelEncoded_Balanced\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "customer_venc",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
